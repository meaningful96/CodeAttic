{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuzAJc0HXO8R",
        "outputId": "f6d77c7b-f9ff-4668-f226-68b38d1f1890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "from torch_geometric.datasets import Amazon\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Yz5T9vurX6Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 불러오기\n",
        "dataset = Amazon(root=\"./tmp/\", name=\"Computers\")\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkbGsfmxX_F4",
        "outputId": "7f7cbc11-4459-4305-f9a1-8d6b860efe66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 training과 test로 분리\n",
        "num_nodes = data.num_nodes\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[:int(0.8 * num_nodes)] = 1  # 80%의 노드를 학습에 사용\n",
        "test_mask = ~train_mask"
      ],
      "metadata": {
        "id": "X2i-JQu3YCjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GATv2 모델 정의\n",
        "class GATv2Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GATv2Net, self).__init__()\n",
        "        self.conv1 = GATv2Conv(in_channels, 128, heads=4)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(128 * 4)\n",
        "        self.conv2 = GATv2Conv(128 * 4, out_channels, heads=1, concat=False)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "ZkdmeVV6YGls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 옵티마이저 초기화\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GATv2Net(dataset.num_features, dataset.num_classes).to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "# Learning Rate 스케쥴러\n",
        "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "\n",
        "# Early Stopping 파라미터\n",
        "patience = 20\n",
        "best_loss = None\n",
        "epochs_no_improve = 0"
      ],
      "metadata": {
        "id": "0AfCMCmXYG6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if best_loss is None:\n",
        "        best_loss = loss.item()\n",
        "    elif best_loss > loss.item():\n",
        "        best_loss = loss.item()\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve == patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvW21n_-YImX",
        "outputId": "0232b63e-16c8-4ac4-85a2-e7eb1400d0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.554509162902832\n",
            "Epoch 2, Loss: 1.5442249774932861\n",
            "Epoch 3, Loss: 1.3311195373535156\n",
            "Epoch 4, Loss: 1.193608045578003\n",
            "Epoch 5, Loss: 1.1307728290557861\n",
            "Epoch 6, Loss: 1.088289499282837\n",
            "Epoch 7, Loss: 1.0560966730117798\n",
            "Epoch 8, Loss: 1.0278639793395996\n",
            "Epoch 9, Loss: 1.0020296573638916\n",
            "Epoch 10, Loss: 0.9761514067649841\n",
            "Epoch 11, Loss: 0.9476819634437561\n",
            "Epoch 12, Loss: 0.932137668132782\n",
            "Epoch 13, Loss: 0.9148510694503784\n",
            "Epoch 14, Loss: 0.8906069993972778\n",
            "Epoch 15, Loss: 0.8745994567871094\n",
            "Epoch 16, Loss: 0.8577199578285217\n",
            "Epoch 17, Loss: 0.8384643197059631\n",
            "Epoch 18, Loss: 0.8234769105911255\n",
            "Epoch 19, Loss: 0.8073405623435974\n",
            "Epoch 20, Loss: 0.7910962104797363\n",
            "Epoch 21, Loss: 0.7790104150772095\n",
            "Epoch 22, Loss: 0.7689658999443054\n",
            "Epoch 23, Loss: 0.7563939690589905\n",
            "Epoch 24, Loss: 0.7464574575424194\n",
            "Epoch 25, Loss: 0.7345621585845947\n",
            "Epoch 26, Loss: 0.7215020060539246\n",
            "Epoch 27, Loss: 0.7133392095565796\n",
            "Epoch 28, Loss: 0.7007505893707275\n",
            "Epoch 29, Loss: 0.6904188990592957\n",
            "Epoch 30, Loss: 0.6820499300956726\n",
            "Epoch 31, Loss: 0.6697222590446472\n",
            "Epoch 32, Loss: 0.6625308990478516\n",
            "Epoch 33, Loss: 0.6552728414535522\n",
            "Epoch 34, Loss: 0.6431887149810791\n",
            "Epoch 35, Loss: 0.6356013417243958\n",
            "Epoch 36, Loss: 0.6255302429199219\n",
            "Epoch 37, Loss: 0.6157488226890564\n",
            "Epoch 38, Loss: 0.6082861423492432\n",
            "Epoch 39, Loss: 0.5993688702583313\n",
            "Epoch 40, Loss: 0.5902379155158997\n",
            "Epoch 41, Loss: 0.5848053693771362\n",
            "Epoch 42, Loss: 0.5762682557106018\n",
            "Epoch 43, Loss: 0.570577085018158\n",
            "Epoch 44, Loss: 0.5605396628379822\n",
            "Epoch 45, Loss: 0.5545966625213623\n",
            "Epoch 46, Loss: 0.5463026165962219\n",
            "Epoch 47, Loss: 0.5428045392036438\n",
            "Epoch 48, Loss: 0.5337038040161133\n",
            "Epoch 49, Loss: 0.5279374718666077\n",
            "Epoch 50, Loss: 0.5192766189575195\n",
            "Epoch 51, Loss: 0.5128841996192932\n",
            "Epoch 52, Loss: 0.5094274282455444\n",
            "Epoch 53, Loss: 0.5054945349693298\n",
            "Epoch 54, Loss: 0.5018993020057678\n",
            "Epoch 55, Loss: 0.49844515323638916\n",
            "Epoch 56, Loss: 0.49411603808403015\n",
            "Epoch 57, Loss: 0.49308040738105774\n",
            "Epoch 58, Loss: 0.49216973781585693\n",
            "Epoch 59, Loss: 0.4874216914176941\n",
            "Epoch 60, Loss: 0.48407039046287537\n",
            "Epoch 61, Loss: 0.47901371121406555\n",
            "Epoch 62, Loss: 0.4763202965259552\n",
            "Epoch 63, Loss: 0.4745877683162689\n",
            "Epoch 64, Loss: 0.46959832310676575\n",
            "Epoch 65, Loss: 0.4675200879573822\n",
            "Epoch 66, Loss: 0.4646812081336975\n",
            "Epoch 67, Loss: 0.4621765911579132\n",
            "Epoch 68, Loss: 0.4570592939853668\n",
            "Epoch 69, Loss: 0.4549062252044678\n",
            "Epoch 70, Loss: 0.45148763060569763\n",
            "Epoch 71, Loss: 0.4473019242286682\n",
            "Epoch 72, Loss: 0.44554388523101807\n",
            "Epoch 73, Loss: 0.44277650117874146\n",
            "Epoch 74, Loss: 0.43856626749038696\n",
            "Epoch 75, Loss: 0.4379805028438568\n",
            "Epoch 76, Loss: 0.4316559433937073\n",
            "Epoch 77, Loss: 0.4321247637271881\n",
            "Epoch 78, Loss: 0.4289722740650177\n",
            "Epoch 79, Loss: 0.425767183303833\n",
            "Epoch 80, Loss: 0.4197530746459961\n",
            "Epoch 81, Loss: 0.4170140326023102\n",
            "Epoch 82, Loss: 0.416667640209198\n",
            "Epoch 83, Loss: 0.4148572087287903\n",
            "Epoch 84, Loss: 0.41237443685531616\n",
            "Epoch 85, Loss: 0.40678057074546814\n",
            "Epoch 86, Loss: 0.40503793954849243\n",
            "Epoch 87, Loss: 0.40149199962615967\n",
            "Epoch 88, Loss: 0.3975813090801239\n",
            "Epoch 89, Loss: 0.3958210051059723\n",
            "Epoch 90, Loss: 0.3929003179073334\n",
            "Epoch 91, Loss: 0.3920864164829254\n",
            "Epoch 92, Loss: 0.38665133714675903\n",
            "Epoch 93, Loss: 0.3848842978477478\n",
            "Epoch 94, Loss: 0.38125357031822205\n",
            "Epoch 95, Loss: 0.38129469752311707\n",
            "Epoch 96, Loss: 0.3782382607460022\n",
            "Epoch 97, Loss: 0.37417781352996826\n",
            "Epoch 98, Loss: 0.3728361427783966\n",
            "Epoch 99, Loss: 0.3701663315296173\n",
            "Epoch 100, Loss: 0.3669784963130951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가 모드로 설정\n",
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "\n",
        "# 테스트 데이터에서의 예측과 실제 라벨\n",
        "pred_test = pred[test_mask].cpu().numpy()\n",
        "y_test = data.y[test_mask].cpu().numpy()\n",
        "\n",
        "# 정확도 계산\n",
        "correct = pred[test_mask].eq(data.y[test_mask]).sum().item()\n",
        "accuracy = correct / test_mask.sum().item()\n",
        "\n",
        "# 정밀도, 재현율, F1 점수 계산\n",
        "precision = precision_score(y_test, pred_test, average='macro')\n",
        "recall = recall_score(y_test, pred_test, average='macro')\n",
        "f1 = f1_score(y_test, pred_test, average='macro')\n",
        "\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test precision: {precision:.4f}\")\n",
        "print(f\"Test recall: {recall:.4f}\")\n",
        "print(f\"Test F1 score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_QaAGV8YKCf",
        "outputId": "9ba0678f-99e3-4dc4-aa6d-171eff7f0c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9124\n",
            "Test precision: 0.8900\n",
            "Test recall: 0.9204\n",
            "Test F1 score: 0.9043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZANbJS8MSWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}